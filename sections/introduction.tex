Currently, character classification for Chinese, Japanese, and Korean (CJK) languages has been very limited. In real-time classification, results have since been improved from prior SVM implementations with convolutional neural networks (CNN). Although referred to here as "CJK" languages/characters the term is used as a collective for the logographic characters used in Hong Kong, Taiwan, and Vietnam in addition to the aforementioned countries. Prior research has generally treated each Chinese character as a whole, ignoring the internal two-dimensional structure within each character. The most recent state-of-the-art work has started to incorporate structure, but only achieves 40.82\% accuracy on unseen handwritten characters, despite 96.66\% accuracy in recall\cite{denseran}. For printed Chinese characters, methods using metadata (multi-typed attributes) pushes the zero-shot performance to 56.6\%\cite{multi-attribute-recognition}, but is unable to translate results to handwriting samples.

Online recognition has more success, and is popular in mobile computing devices\cite{online-handwriting}, seeing heavy use in input method editors (IME). However, their reliance on temporal data makes them ineffective in OCR, and causes failures for incorrect stroke order.

Despite the over 40,000 characters needed for complete modern day coverage in present day Chinese, existing research has been reliant on the 3,755 characters of GB2312-80's level-1 set and the CASIA handwriting dataset\cite{casia-handwriting-db}. These characters form the "base set" needed for general literacy of Chinese. For Japanese, a set of 2,136 characters for basic literacy, the \textit{jōyō kanji}, is published by the Japanese Ministry of Education.

In other computer vision classification tasks, recognition across over 9,000 classes has been achieved, in the YOLOv2 architecture\cite{yolo}. It is unsurprising that the handwriting recognition approaches in similar architectures all boast recognition rates of slightly over 96\% for the 3,755 class size. The top three approaches are based on GoogLeNet \cite{hccr-googlenet}, ResNet \cite{multi-attribute-recognition}, and DenseNet \cite{denseran}.

The poor performance on characters landing outside of the level-1 metric is a problem that has not yet been solved. The current state-of-the-art method in both zero-shot and recall, DenseRAN\cite{denseran}, utilizes attention, but can fail easily if the wrong path in attention is taken. Thus, the intuition of this proposal is that a bidirectional and hierarchical attention mechanism is necessary within the Chinese, and by extension, CJK character classification task.
Bidirectional graph traversal allows for an efficient and correct encoding sequence of characters to be built. This intuition serves as the basis of the structure necessary to achieve performance in the zero-shot case, as well as recognition across the over 40,000 classes of Chinese logographic characters of modern use.
