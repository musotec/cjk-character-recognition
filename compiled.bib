 @misc{adobe-ids,
 title={IDS + OpenType: Pseudo-encoding Unencoded Glyphs}, url={https://blogs.adobe.com/CCJKType/2014/03/ids-opentype.html}, journal={CJK Type Blog}, author={Lunde, Ken}, year={2014}, month={Mar}}  
@InProceedings{attention-hanzi,
author="Sheng, Fenfen
and Zhai, Chuanlei
and Chen, Zhineng
and Xu, Bo",
editor="Liu, Derong
and Xie, Shengli
and Li, Yuanqing
and Zhao, Dongbin
and El-Alfy, El-Sayed M.",
title="End-to-End Chinese Image Text Recognition with Attention Model",
booktitle="Neural Information Processing",
year="2017",
publisher="Springer International Publishing",
address="Cham",
pages="180--189",
abstract="This paper presents an attention-based model for end-to-end Chinese image text recognition. The proposed model includes an encoder and a decoder. For each input text image, the encoder part firstly combines deep convolutional layers with bidirectional Recurrent Neural Network to generate an ordered, high-level feature sequence, which could avoid the complicated text segmentation pre-processing. Then in the decoder, a recurrent network with attention mechanism is developed to generate text line output, enabling the model to selectively exploit image features from the encoder correspondingly. The whole segmentation-free model allows end-to-end training within a standard backpropagation algorithm. Extensive experiments demonstrate significant performance improvements comparing to baseline systems. Furthermore, qualitative analysis reveals that the proposed model could learn the alignment between input and output in accordance with the intuition.",
isbn="978-3-319-70090-8"
}
@article{bert,
  author    = {Jacob Devlin and
               Ming{-}Wei Chang and
               Kenton Lee and
               Kristina Toutanova},
  title     = {{BERT:} Pre-training of Deep Bidirectional Transformers for Language
               Understanding},
  journal   = {CoRR},
  volume    = {abs/1810.04805},
  year      = {2018},
  url       = {http://arxiv.org/abs/1810.04805},
  archivePrefix = {arXiv},
  eprint    = {1810.04805},
  timestamp = {Tue, 30 Oct 2018 20:39:56 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1810-04805.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@InProceedings{blstm-sentence-level,
author="Zhai, Chuanlei
and Chen, Zhineng
and Li, Jie
and Xu, Bo",
editor="Tan, Tieniu
and Li, Xuelong
and Chen, Xilin
and Zhou, Jie
and Yang, Jian
and Cheng, Hong",
title="Chinese Image Text Recognition with BLSTM-CTC: A Segmentation-Free Method",
booktitle="Pattern Recognition",
year="2016",
publisher="Springer Singapore",
address="Singapore",
pages="525--536",
abstract="This paper presents BLSTM-CTC (bidirectional LSTM-Connectionist Temporal Classification), a novel scheme to tackle the Chinese image text recognition problem. Different from traditional methods that perform the recognition on the single character level, the input of BLSTM-CTC is an image text composed of a line of characters and the output is a recognized text sequence, where the recognition is carried out on the whole image text level. To train a neural network for this challenging task, we collect over 2 million news titles from which we generate over 1 million noisy image texts, covering almost the vast majority of common Chinese characters. With these training data, a RNN training procedure is conducted to learn the recognizer. We also carry out some adaptations on the neural network to make it suitable for real scenarios. Experiments on text images from 13 TV channels demonstrate the effectiveness of the proposed pipeline. The results all outperform those of a baseline system.",
isbn="978-981-10-3005-5"
}

 
@inproceedings{casia-handwriting-db,
author = {Liu, Cheng-Lin and Yin, Fei and Wang, Da-Han and Wang, Qiu-Feng},
year = {2011},
month = {10},
pages = {37 - 41},
title = {CASIA Online and Offline Chinese Handwriting Databases},
journal = {Proceedings of the International Conference on Document Analysis and Recognition, ICDAR},
doi = {10.1109/ICDAR.2011.17}
}
 @article{cjk-stroop,
 title={Lexical processing of Chinese sub-character components: Semantic activation of phonetic radicals as revealed by the Stroop effect}, volume={7}, DOI={10.1038/s41598-017-15536-w}, number={1}, journal={Scientific Reports}, author={Yeh, Su-Ling and Chou, Wei-Lun and Ho, Pokuan}, year={2017}, month={Nov}}  
@article{compound-ideographs,
 ISSN = {00913723},
 URL = {http://www.jstor.org/stable/23754815},
 abstract = {Many Western readers currently accept an account of the early evolution of Chinese script due to William Boltz, according to whom all graphs other than simple pictographs originated as phonetic—semantic compounds. This contrasts with the traditional Chinese account of 六書 'six writings', according to which some graphs were compounds of separate elements each chosen for their meaning rather than their sound. This paper argues that (while the 'six writings' theory had flaws) with respect to that central issue it is correct, and Boltz is mistaken. 在西方學界，人們普遍接受 William Boltz 關于漢字早期發展的理論. Boltz 認爲除了象形字以外，所有其他的漢字都應該源于形聲字。 Boltz 的理論同傳統的六書理論是相抵觸的. 在許慎的六書理論中，有一組漢字，也就是許慎所定義的會意字，是由兩個或兩個以上的符號因爲其各自代表的意義而結合起來所形成的。 在這篇論文中，我們將證明在會意字這個漢字範疇上，六書理論是正確的，儘管其理論有其_身的缺陷，而 Boltz 的理論是錯誤的。},
 author = {Geoffrey Sampson and Chen Zhiqun and 散復生 and 陳志群},
 journal = {Journal of Chinese Linguistics},
 number = {2},
 pages = {255--272},
 publisher = {[Chinese University Press, Project on Linguistic Analysis]},
 title = {THE REALITY OF COMPOUND IDEOGRAPHS / 論會意字的眞實性},
 volume = {41},
 year = {2013}
}

 
@article{conv-chinese-character-synthesis,
  author    = {Xiaohang Ren and
               Kai Chen and
               Jun Sun},
  title     = {A {CNN} Based Scene Chinese Text Recognition Algorithm With Synthetic
               Data Engine},
  journal   = {CoRR},
  volume    = {abs/1604.01891},
  year      = {2016},
  url       = {http://arxiv.org/abs/1604.01891},
  archivePrefix = {arXiv},
  eprint    = {1604.01891},
  timestamp = {Mon, 13 Aug 2018 16:49:03 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/Ren0016.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{denseran,
  author    = {Wenchao Wang and
               Jianshu Zhang and
               Jun Du and
               Zi{-}Rui Wang and
               Yixing Zhu},
  title     = {DenseRAN for Offline Handwritten Chinese Character Recognition},
  journal   = {CoRR},
  volume    = {abs/1808.04134},
  year      = {2018},
  url       = {http://arxiv.org/abs/1808.04134},
  archivePrefix = {arXiv},
  eprint    = {1808.04134},
  timestamp = {Sun, 02 Sep 2018 15:01:57 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1808-04134.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{fast-encoded-han-search,
  author    = {Matthew Skala},
  title     = {A Structural Query System for Han Characters},
  journal   = {CoRR},
  volume    = {abs/1404.5585},
  year      = {2014},
  url       = {http://arxiv.org/abs/1404.5585},
  archivePrefix = {arXiv},
  eprint    = {1404.5585},
  timestamp = {Mon, 13 Aug 2018 16:46:29 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/Skala14.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{hccr-googlenet,
  author    = {Zhuoyao Zhong and
               Lianwen Jin and
               Zecheng Xie},
  title     = {High Performance Offline Handwritten Chinese Character Recognition
               Using GoogLeNet and Directional Feature Maps},
  journal   = {CoRR},
  volume    = {abs/1505.04925},
  year      = {2015},
  url       = {http://arxiv.org/abs/1505.04925},
  archivePrefix = {arXiv},
  eprint    = {1505.04925},
  timestamp = {Mon, 13 Aug 2018 16:47:37 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/ZhongJX15.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

 
@article{imagenet,
Author = {Olga Russakovsky and Jia Deng and Hao Su and Jonathan Krause and Sanjeev Satheesh and Sean Ma and Zhiheng Huang and Andrej Karpathy and Aditya Khosla and Michael Bernstein and Alexander C. Berg and Li Fei-Fei},
Title = {{ImageNet Large Scale Visual Recognition Challenge}},
Year = {2015},
journal   = {International Journal of Computer Vision (IJCV)},
doi = {10.1007/s11263-015-0816-y},
volume={115},
number={3},
pages={211-252}
}
@inproceedings{ime-compression,
    title = "Efficient dictionary and language model compression for input method editors",
    author = "Kudo, Taku  and
      Hanaoka, Toshiyuki  and
      Mukai, Jun  and
      Tabata, Yusuke  and
      Komatsu, Hiroyuki",
    booktitle = "Proceedings of the Workshop on Advances in Text Input Methods ({WTIM} 2011)",
    month = nov,
    year = "2011",
    address = "Chiang Mai, Thailand",
    publisher = "Asian Federation of Natural Language Processing",
    url = "https://www.aclweb.org/anthology/W11-3503",
    pages = "19--25",
}
@misc{kanjivg,
title={KanjiVG},
url={http://kanjivg.tagaini.net/},
journal={KanjiVG, a description of the sinographs (or kanji) used by the Japanese language},
author={Apel, Ulrich},
year={2009}
} 
@inproceedings{louds-structure,
author = {Jacobson, G.},
title = {Space-Efficient Static Trees and Graphs},
year = {1989},
isbn = {0818619821},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/SFCS.1989.63533},
doi = {10.1109/SFCS.1989.63533},
abstract = {Data structures that represent static unlabeled trees and planar graphs are developed. The structures are more space efficient than conventional pointer-based representations, but (to within a constant factor) they are just as time efficient for traversal operations. For trees, the data structures described are asymptotically optimal: there is no other structure that encodes n-node trees with fewer bits per node, as N grows without bound. For planar graphs (and for all graphs of bounded page number), the data structure described uses linear space: it is within a constant factor of the most succinct representation.},
booktitle = {Proceedings of the 30th Annual Symposium on Foundations of Computer Science},
pages = {549–554},
numpages = {6},
keywords = {data structure, n-node trees, traversal operations, bounded page number, static unlabeled trees, bits per node, data structures, planar graphs},
series = {SFCS '89}
}
 @misc{meme-text,
 title={Psycholinguistic evidence on scrambled letters in reading}, url={https://www.mrc-cbu.cam.ac.uk/people/matt.davis/cmabridge/}, journal={MRC Cognition and Brain Sciences Unit}, author={Davis, Matt}, year={2012}}  
@article{multi-attribute-recognition,
  author    = {Sheng He and
               Lambert Schomaker},
  title     = {Open Set Chinese Character Recognition using Multi-typed Attributes},
  journal   = {CoRR},
  volume    = {abs/1808.08993},
  year      = {2018},
  url       = {http://arxiv.org/abs/1808.08993},
  archivePrefix = {arXiv},
  eprint    = {1808.08993},
  timestamp = {Mon, 03 Sep 2018 13:36:40 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1808-08993.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{offline-kr,
title = "Off-line handwritten Korean character recognition based on stroke extraction and representation",
journal = "Pattern Recognition Letters",
volume = "15",
number = "12",
pages = "1245 - 1253",
year = "1994",
issn = "0167-8655",
doi = "https://doi.org/10.1016/0167-8655(94)90115-5",
url = "http://www.sciencedirect.com/science/article/pii/0167865594901155",
author = "Pyeoung Kee Kim and Hang Joon Kim",
keywords = "Character recognition, Korean character, Stroke segment, Stroke extraction, Stroke relationships, Grapheme",
abstract = "In this paper, we propose an off-line recognition method for handwritten Korean characters based on stroke extraction and representation. To recognize handwritten Korean characters, it is required to extract strokes and stroke sequence to describe an input of two-dimensional character as one-dimensional representation. We define 28 primitive strokes to represent characters and introduce 300 stroke separation rules to extract proper strokes from Korean characters. To find a stroke sequence, we use stroke code and stroke relationship between consecutive strokes. The input characters are recognized by using character recognition trees. The proposed method has been tested for the most frequently used 1000 characters by 400 different writers and showed recognition rate of 94.3%."
} 
@article{online-ch,
author = {Liu, Cheng-Lin and Jaeger, Stefan and Nakagawa, Masaki},
year = {2004},
month = {03},
pages = {198-213},
title = {Online Recognition of Chinese Characters: The State-of-the-Art},
volume = {26},
journal = {IEEE transactions on pattern analysis and machine intelligence},
doi = {10.1109/TPAMI.2004.1262182}
} 
@article{online-handwriting,
title	= {Multi-Language Online Handwriting Recognition},
author	= {Daniel Keysers and Thomas Deselaers and Henry A. Rowley and Li-Lun Wang and Victor Carbune},
year	= {2016},
URL	= {http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7478642},
journal	= {IEEE Transactions on Pattern Analysis and Machine Intelligence}
}

 
@article{online-ja,
author = {Jaeger, Stefan and Liu, Cheng-Lin and Nakagawa, Masaki},
year = {2003},
month = {10},
pages = {75-88},
title = {The state of the art in Japanese online handwriting recognition compared to techniques in western handwriting recognition},
volume = {6},
journal = {International Journal on Document Analysis and Recognition},
doi = {10.1007/s10032-003-0107-y}
} 
@article{residual-attention,
  author    = {Fei Wang and
               Mengqing Jiang and
               Chen Qian and
               Shuo Yang and
               Cheng Li and
               Honggang Zhang and
               Xiaogang Wang and
               Xiaoou Tang},
  title     = {Residual Attention Network for Image Classification},
  journal   = {CoRR},
  volume    = {abs/1704.06904},
  year      = {2017},
  url       = {http://arxiv.org/abs/1704.06904},
  archivePrefix = {arXiv},
  eprint    = {1704.06904},
  timestamp = {Fri, 18 Dec 2020 08:50:35 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/WangJQYLZWT17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
} 
@inproceedings{sparse-tree-boosting,
author = {Kudo, Taku and Suzuki, Jun and Isozaki, Hideki},
title = {Boosting-Based Parse Reranking with Subtree Features},
year = {2005},
publisher = {Association for Computational Linguistics},
address = {USA},
url = {https://doi.org/10.3115/1219840.1219864},
doi = {10.3115/1219840.1219864},
abstract = {This paper introduces a new application of boosting for parse reranking. Several parsers have been proposed that utilize the all-subtrees representation (e.g., tree kernel and data oriented parsing). This paper argues that such an all-subtrees representation is extremely redundant and a comparable accuracy can be achieved using just a small set of subtrees. We show how the boosting algorithm can be applied to the all-subtrees representation and how it selects a small and relevant feature set efficiently. Two experiments on parse reranking show that our method achieves comparable or even better performance than kernel methods and also improves the testing efficiency.},
booktitle = {Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics},
pages = {189–196},
numpages = {8},
location = {Ann Arbor, Michigan},
series = {ACL '05}
}

   
@article{transformers,
  author    = {Ashish Vaswani and
               Noam Shazeer and
               Niki Parmar and
               Jakob Uszkoreit and
               Llion Jones and
               Aidan N. Gomez and
               Lukasz Kaiser and
               Illia Polosukhin},
  title     = {Attention Is All You Need},
  journal   = {CoRR},
  volume    = {abs/1706.03762},
  year      = {2017},
  url       = {http://arxiv.org/abs/1706.03762},
  archivePrefix = {arXiv},
  eprint    = {1706.03762},
  timestamp = {Mon, 13 Aug 2018 16:48:37 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/VaswaniSPUJGKP17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

 
@misc{unicode-ids,
title={The Unicode Standard Version 13.0 – Core Specification}, url={https://www.unicode.org/versions/Unicode13.0.0/ch18.pdf#page=24}, journal={The Unicode Standard Version 13.0 – 18.2  Ideographic Description Characters}, year={2020}, month={Mar}}  
@misc{wenlin,
title={Character Description Language (CDL)}, url={http://www.wenlin.com/cdl}, journal={An XML application for rendering and indexing Han (CJKV) characters}, publisher={Wenlin Institute, Inc. SPC}, author={Bishop, Tom and Cook, Richard}, year={2018}}  
@misc{wikipedia-han-unification,
title={Han unification - Differences for the same Unicode character (U+8FD4) in regional versions of Source Han Sans}, url={https://en.wikipedia.org/wiki/Han_unification#/media/File:Source_Han_Sans_Version_Difference.svg}, journal={Wikipedia}, publisher={Wikimedia Foundation}, author={User:Emphrase}, year={2020}, month={Dec}}  
@article{wordnet,
author = {Miller, George A.},
title = {WordNet: A Lexical Database for English},
year = {1995},
issue_date = {Nov. 1995},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {38},
number = {11},
issn = {0001-0782},
url = {https://doi.org/10.1145/219717.219748},
doi = {10.1145/219717.219748},
abstract = {Because meaningful sentences are composed of meaningful words, any system that hopes to process natural languages as people do must have information about words and their meanings. This information is traditionally provided through dictionaries, and machine-readable dictionaries are now widely available. But dictionary entries evolved for the convenience of human readers, not for machines. WordNet1 provides a more effective combination of traditional lexicographic information and modern computing. WordNet is an online lexical database designed for use under program control. English nouns, verbs, adjectives, and adverbs are organized into sets of synonyms, each representing a lexicalized concept. Semantic relations link the synonym sets [4].},
journal = {Commun. ACM},
month = nov,
pages = {39–41},
numpages = {3}
} 
@article{yolo,
  author    = {Joseph Redmon and
               Ali Farhadi},
  title     = {{YOLO9000:} Better, Faster, Stronger},
  journal   = {CoRR},
  volume    = {abs/1612.08242},
  year      = {2016},
  url       = {http://arxiv.org/abs/1612.08242},
  archivePrefix = {arXiv},
  eprint    = {1612.08242},
  timestamp = {Mon, 13 Aug 2018 16:48:25 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/RedmonF16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

 
